# NERD
Evolution of Discrete data with Reinforcement Learning

https://gananath.github.io/nerd.html


![NERD](https://raw.githubusercontent.com/Gananath/gananath.github.io/master/images/nerd.jpg)

# Requirements
- pytorch 1.3
- pysmiles 1.0
- sklearn

# Current result
## Sequence Generation
**Epoch: 10000 Reward: -1000.0 Loss: -0.73**
```
CCBCCCBCBCC|C||||CC|||||||||||||||||||||||||||... -10.0 -0.501915 
CCBCCCBCBCC|C||||CC|||||||||||||||||||||||||||... -10.0 -0.502028 
CCBCCCBCBCC|C||||CC|||||||||||||||||||||||||||... -10.0 -0.502080
```
## Image Generation
> https://github.com/Gananath/NERD/tree/master/NERD_IMAGES
![nerd_mnist](https://raw.githubusercontent.com/Gananath/NERD/master/NERD_IMAGES/nerd_mnist.png)

# Cite
**DOI**: https://doi.org/10.5281/zenodo.3518054

```
@misc{gananath2016,
  author = {Gananath, R.},
  title = {NERD},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Gananath/NERD}},
  doi = {10.5281/zenodo.3518054}
}
```
